# ðŸŽµ GestureSynth A-Vision-Based-Hand-Gesture-System-for-Expressive-Musical-Performance
Course Project For Foundations of Human Computer Interaction



**Turn your hand gestures into real-time MIDI music** using just a webcam. No keyboard, no MIDI controller â€” just your hands and a computer.

GestureSynth uses **MediaPipe** for hand tracking and **MIDI** for musical output, with optional **LLM-powered musical feedback** to help you improve your expressive performance.

https://github.com/user/GestureSynth/assets/123456789/gesture_demo.gif

---

## âœ¨ Features

- Real-time hand-to-MIDI conversion
- Pitch mapped to vertical hand position
- Velocity mapped to horizontal/vertical position or fixed
- Chord mode (Major, Minor, 7th)
- MIDI recording & export (.mid files)
- **Adaptive Mode**: LLM analyzes your performance and suggests parameter tweaks
- Responsive UI with gesture preview and note guide

---

## ðŸš€ Quick Start

### 1. Clone the repo
```bash
git clone https://github.com/your-username/GestureSynth.git
cd GestureSynth
